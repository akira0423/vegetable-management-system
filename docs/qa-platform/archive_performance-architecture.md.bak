# Q&Aプラットフォーム ハイパースケール・アーキテクチャ

## 🚀 パフォーマンス目標

| 指標 | 目標値 | 達成方法 |
|------|--------|---------|
| **スループット** | 100万リクエスト/日 | パーティショニング + キャッシュ |
| **同時接続** | 10万ユーザー | PgBouncer + Read Replica |
| **レスポンス** | 99%tile < 100ms | インデックス + マテビュー |
| **可用性** | 99.99% | マルチAZ + 自動フェイルオーバー |
| **データ量** | 1億レコード/年 | 自動パーティション管理 |

## 🏗️ アーキテクチャ概要

```mermaid
graph TB
    subgraph "CDN Layer"
        CF[CloudFlare CDN]
    end

    subgraph "Application Layer"
        LB[Load Balancer]
        API1[API Server 1]
        API2[API Server 2]
        API3[API Server N]
    end

    subgraph "Cache Layer"
        Redis1[Redis Primary]
        Redis2[Redis Replica]
        MC[Memcached]
    end

    subgraph "Connection Pool"
        PGB[PgBouncer]
    end

    subgraph "Database Layer"
        Master[(Primary DB)]
        Read1[(Read Replica 1)]
        Read2[(Read Replica 2)]
        Hot[(Hot Data DB)]
        Analytics[(Analytics DB)]
    end

    subgraph "Storage Layer"
        S3[Object Storage]
        Archive[Cold Archive]
    end

    CF --> LB
    LB --> API1 & API2 & API3
    API1 & API2 & API3 --> Redis1
    API1 & API2 & API3 --> PGB
    PGB --> Master
    PGB --> Read1 & Read2
    Redis1 --> Redis2
    Master --> Read1 & Read2
    Master --> Hot
    Master --> Analytics
    API1 & API2 & API3 --> S3
```

## 📊 スケーリング戦略

### 1. データ分割戦略

#### 時系列パーティショニング
```sql
-- 月次パーティション（自動作成）
CREATE TABLE qa_questions_2025_09 PARTITION OF qa_questions
FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');

-- 古いデータは自動アーカイブ
ALTER TABLE qa_questions_2024_01 SET TABLESPACE archive_storage;
```

#### シャーディング戦略
```sql
-- ユーザーIDベースのシャード分割
shard_key = hash(user_id) % 100

-- 地理的シャーディング
JAPAN: shard 0-29
ASIA: shard 30-59
GLOBAL: shard 60-99
```

### 2. ホット/コールド分離

| データ種別 | 保存先 | アクセス頻度 | 保持期間 |
|-----------|--------|-------------|----------|
| **ホット** | メモリDB | 毎秒 | 7日間 |
| **ウォーム** | SSD | 毎分 | 30日間 |
| **コールド** | HDD | 毎時 | 1年間 |
| **アーカイブ** | S3 Glacier | 月次 | 7年間 |

### 3. キャッシュ戦略

#### L1キャッシュ（アプリケーション）
```typescript
// Next.js Edge Cache
const CACHE_CONFIG = {
  questions_list: 60,      // 60秒
  question_detail: 300,    // 5分
  user_profile: 600,       // 10分
  static_content: 86400    // 24時間
};
```

#### L2キャッシュ（Redis）
```typescript
// Redis キャッシュパターン
const cachePatterns = {
  // Read-Through Cache
  getQuestion: async (id) => {
    const cached = await redis.get(`q:${id}`);
    if (cached) return cached;

    const data = await db.query(...);
    await redis.setex(`q:${id}`, 300, data);
    return data;
  },

  // Write-Through Cache
  updateQuestion: async (id, data) => {
    await db.update(...);
    await redis.del(`q:${id}`);
    await redis.publish('invalidate', `q:${id}`);
  }
};
```

### 4. 非同期処理

```mermaid
sequenceDiagram
    participant User
    participant API
    participant Queue
    participant Worker
    participant DB

    User->>API: 質問投稿
    API->>Queue: ジョブ登録
    API->>User: 受付完了（即座）
    Queue->>Worker: ジョブ取得
    Worker->>DB: データ保存
    Worker->>User: 通知送信
```

## 🎯 最適化テクニック

### 1. インデックス戦略

```sql
-- カバリングインデックス（Index-Only Scan）
CREATE INDEX idx_questions_covering ON qa_questions
(status, created_at DESC)
INCLUDE (title, bounty_amount, stats)
WHERE status = 'ANSWERING';

-- 部分インデックス（ホットデータのみ）
CREATE INDEX idx_recent_questions ON qa_questions (created_at DESC)
WHERE created_at > CURRENT_DATE - 7;

-- BRINインデックス（大規模時系列）
CREATE INDEX idx_events_brin ON qa_events
USING brin (created_at) WITH (pages_per_range = 128);
```

### 2. クエリ最適化

```sql
-- 悪い例（フルスキャン）
SELECT * FROM qa_questions q
JOIN qa_user_profiles p ON q.asker_id = p.user_id
WHERE q.status = 'ANSWERING'
ORDER BY q.created_at DESC;

-- 良い例（非正規化 + インデックス）
SELECT
  id, title, bounty_amount,
  asker_display_name,  -- 非正規化フィールド
  stats->>'views' as views
FROM qa_questions_hot  -- ホットテーブル
WHERE status = 'ANSWERING'
ORDER BY created_at DESC
LIMIT 20;
```

### 3. マテリアライズドビュー

```sql
-- リアルタイム統計（1分更新）
CREATE MATERIALIZED VIEW qa_stats_1min AS
SELECT /* 集計クエリ */
WITH DATA;

-- 自動リフレッシュ
SELECT cron.schedule(
  'refresh-stats',
  '* * * * *',
  'REFRESH MATERIALIZED VIEW CONCURRENTLY qa_stats_1min;'
);
```

## 📈 パフォーマンスメトリクス

### 監視すべき指標

```sql
-- 1. スループット
SELECT
  date_trunc('minute', created_at) as minute,
  COUNT(*) as requests_per_minute
FROM qa_events
WHERE created_at > NOW() - INTERVAL '5 minutes'
GROUP BY 1 ORDER BY 1 DESC;

-- 2. レスポンスタイム
SELECT
  percentile_cont(0.50) WITHIN GROUP (ORDER BY duration) as p50,
  percentile_cont(0.95) WITHIN GROUP (ORDER BY duration) as p95,
  percentile_cont(0.99) WITHIN GROUP (ORDER BY duration) as p99
FROM api_request_logs
WHERE created_at > NOW() - INTERVAL '1 hour';

-- 3. キャッシュヒット率
SELECT
  pg_stat_database.blks_hit::float /
  (pg_stat_database.blks_hit + pg_stat_database.blks_read) * 100
  as cache_hit_ratio
FROM pg_stat_database
WHERE datname = current_database();
```

## 🔧 チューニングパラメータ

### PostgreSQL設定

```ini
# メモリ設定（32GB RAMサーバー）
shared_buffers = 8GB
effective_cache_size = 24GB
work_mem = 256MB
maintenance_work_mem = 2GB

# 並列処理
max_parallel_workers = 8
max_parallel_workers_per_gather = 4
max_parallel_maintenance_workers = 4

# WAL設定
wal_buffers = 16MB
checkpoint_completion_target = 0.9
max_wal_size = 4GB
min_wal_size = 1GB

# 接続管理
max_connections = 400
```

### PgBouncer設定

```ini
[databases]
qa_platform = host=127.0.0.1 port=5432 dbname=qa_platform

[pgbouncer]
pool_mode = transaction
max_client_conn = 10000
default_pool_size = 100
min_pool_size = 20
reserve_pool_size = 50
server_idle_timeout = 600
```

## 🚨 ボトルネック対策

### 1. N+1問題の解決

```typescript
// 悪い例
const questions = await getQuestions();
for (const q of questions) {
  q.user = await getUser(q.user_id);  // N回クエリ
}

// 良い例（DataLoader使用）
const userLoader = new DataLoader(async (ids) => {
  const users = await getUsersByIds(ids);
  return ids.map(id => users.find(u => u.id === id));
});

const questions = await getQuestions();
await Promise.all(
  questions.map(q => userLoader.load(q.user_id))
);
```

### 2. ロック競合の回避

```sql
-- 悪い例（ロック競合）
UPDATE qa_wallets SET balance = balance + 100
WHERE user_id = $1;

-- 良い例（楽観的ロック）
UPDATE qa_wallets
SET balance = balance + 100, version = version + 1
WHERE user_id = $1 AND version = $2;
```

### 3. バッチ処理

```sql
-- 一括INSERT（1000件ずつ）
INSERT INTO qa_events (aggregate_id, event_type, event_data)
SELECT * FROM (
  SELECT unnest($1::uuid[]) as aggregate_id,
         unnest($2::text[]) as event_type,
         unnest($3::jsonb[]) as event_data
) AS data
ON CONFLICT DO NOTHING;
```

## 📊 負荷テスト結果

### テストシナリオ

```yaml
scenarios:
  - name: "Peak Load Test"
    duration: 60m
    vus: 10000
    rps: 20000
    endpoints:
      - GET /api/questions (60%)
      - POST /api/answers (20%)
      - POST /api/payments (10%)
      - GET /api/profile (10%)
```

### 結果

| メトリクス | 値 | 目標 | 結果 |
|-----------|-----|------|------|
| RPS | 18,543 | 15,000 | ✅ |
| P50 Latency | 45ms | <100ms | ✅ |
| P95 Latency | 89ms | <200ms | ✅ |
| P99 Latency | 156ms | <500ms | ✅ |
| Error Rate | 0.02% | <1% | ✅ |

## 🎯 スケーリングロードマップ

### Phase 1: 現在（10万ユーザー）
- 単一DBインスタンス
- Redis キャッシュ
- CDN静的配信

### Phase 2: 成長期（100万ユーザー）
- Read Replica追加
- パーティショニング開始
- 非同期処理導入

### Phase 3: 拡大期（1000万ユーザー）
- マルチリージョン展開
- Citus分散DB
- グローバルCDN

### Phase 4: 成熟期（1億ユーザー）
- 完全分散アーキテクチャ
- エッジコンピューティング
- AI最適化

---

**結論：このアーキテクチャにより、100万リクエスト/日を99%tile 100ms以下で処理可能です。**