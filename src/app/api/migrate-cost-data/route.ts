import { NextRequest, NextResponse } from 'next/server'
import { createServiceClient } from '@/lib/supabase/server'

export async function POST(request: NextRequest) {
  try {
    const supabase = await createServiceClient()
    const body = await request.json()
    const { company_id, dry_run = true } = body

    console.log('ğŸ”„ ã‚³ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹:', { company_id, dry_run })

    // Step 1: æ—¢å­˜ã®work_reportsã‹ã‚‰ã‚³ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—
    const { data: workReports, error: reportsError } = await supabase
      .from('work_reports')
      .select('id, notes, work_type, work_date, created_at')
      .eq('company_id', company_id)
      .not('notes', 'is', null)

    if (reportsError) {
      console.error('âŒ ä½œæ¥­ãƒ¬ãƒãƒ¼ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼:', reportsError)
      return NextResponse.json(
        { error: 'Failed to fetch work reports', details: reportsError },
        { status: 500 }
      )
    }

    console.log(`ğŸ“Š å–å¾—ã—ãŸä½œæ¥­ãƒ¬ãƒãƒ¼ãƒˆæ•°: ${workReports?.length || 0}`)

    // Step 2: notesã‹ã‚‰ã‚³ã‚¹ãƒˆæƒ…å ±ã‚’æŠ½å‡º
    const costDataToMigrate = []
    for (const report of workReports || []) {
      try {
        const notes = typeof report.notes === 'string' ? JSON.parse(report.notes) : report.notes
        if (notes?.estimated_cost && notes.estimated_cost > 0) {
          costDataToMigrate.push({
            work_report_id: report.id,
            original_cost: notes.estimated_cost,
            work_type: report.work_type,
            work_date: report.work_date,
            created_at: report.created_at
          })
        }
      } catch (parseError) {
        console.warn(`âš ï¸ JSONè§£æå¤±æ•— (report_id: ${report.id}):`, parseError)
      }
    }

    console.log(`ğŸ’° å¤‰æ›å¯¾è±¡ã®ã‚³ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°: ${costDataToMigrate.length}`)

    // Step 3: ä¼šè¨ˆé …ç›®ãƒã‚¹ã‚¿ã‹ã‚‰é©åˆ‡ãªæ”¯å‡ºé …ç›®ã‚’å–å¾—
    const { data: accountingItems, error: itemsError } = await supabase
      .from('accounting_items')
      .select('id, code, name, type')
      .eq('type', 'expense')

    if (itemsError) {
      console.error('âŒ ä¼šè¨ˆé …ç›®å–å¾—ã‚¨ãƒ©ãƒ¼:', itemsError)
      return NextResponse.json(
        { error: 'Failed to fetch accounting items', details: itemsError },
        { status: 500 }
      )
    }

    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ”¯å‡ºé …ç›®ã‚’æ±ºå®šï¼ˆã€Œãã®ä»–è²»ç”¨ã€ã¾ãŸã¯æœ€åˆã®æ”¯å‡ºé …ç›®ï¼‰
    const defaultExpenseItem = accountingItems?.find(item => 
      item.name.includes('ãã®ä»–') || item.name.includes('è²»ç”¨')
    ) || accountingItems?.[0]

    if (!defaultExpenseItem) {
      return NextResponse.json(
        { error: 'No expense accounting items found' },
        { status: 400 }
      )
    }

    console.log(`ğŸ“ ä½¿ç”¨ã™ã‚‹ä¼šè¨ˆé …ç›®: ${defaultExpenseItem.name} (${defaultExpenseItem.code})`)

    // Step 4: ä¼šè¨ˆãƒ‡ãƒ¼ã‚¿ã¸ã®å¤‰æ›æº–å‚™
    const accountingDataToInsert = costDataToMigrate.map(cost => ({
      work_report_id: cost.work_report_id,
      accounting_item_id: defaultExpenseItem.id,
      amount: cost.original_cost,
      custom_item_name: `ãƒ¬ã‚¬ã‚·ãƒ¼ã‚³ã‚¹ãƒˆ (${cost.work_type})`,
      notes: `æ—§ã‚³ã‚¹ãƒˆæƒ…å ±ã‹ã‚‰è‡ªå‹•ç§»è¡Œ (${cost.work_date})`,
      is_ai_recommended: false
    }))

    // Step 5: Dry Run ã¾ãŸã¯å®Ÿéš›ã®å®Ÿè¡Œ
    if (dry_run) {
      console.log('ğŸ§ª DRY RUN ãƒ¢ãƒ¼ãƒ‰ - å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿å¤‰æ›´ã¯è¡Œã„ã¾ã›ã‚“')
      return NextResponse.json({
        success: true,
        dry_run: true,
        summary: {
          total_reports_checked: workReports?.length || 0,
          cost_data_found: costDataToMigrate.length,
          target_accounting_item: defaultExpenseItem.name,
          sample_conversion: costDataToMigrate.slice(0, 3),
          sample_accounting_data: accountingDataToInsert.slice(0, 3)
        },
        message: 'Migration preview completed successfully'
      })
    }

    // å®Ÿéš›ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    console.log('ğŸ”¥ å®Ÿéš›ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...')

    // æ—¢å­˜ã®å¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
    const { data: existingData } = await supabase
      .from('work_report_accounting')
      .select('work_report_id')
      .in('work_report_id', costDataToMigrate.map(c => c.work_report_id))

    const existingReportIds = existingData?.map(d => d.work_report_id) || []
    const newDataToInsert = accountingDataToInsert.filter(
      item => !existingReportIds.includes(item.work_report_id)
    )

    console.log(`âœ¨ æ–°è¦æŒ¿å…¥ãƒ‡ãƒ¼ã‚¿æ•°: ${newDataToInsert.length}`)

    if (newDataToInsert.length > 0) {
      const { data: insertedData, error: insertError } = await supabase
        .from('work_report_accounting')
        .insert(newDataToInsert)
        .select()

      if (insertError) {
        console.error('âŒ ä¼šè¨ˆãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ã‚¨ãƒ©ãƒ¼:', insertError)
        return NextResponse.json(
          { error: 'Failed to insert accounting data', details: insertError },
          { status: 500 }
        )
      }

      console.log(`âœ… ${insertedData?.length || 0}ä»¶ã®ä¼šè¨ˆãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥å®Œäº†`)
    }

    return NextResponse.json({
      success: true,
      dry_run: false,
      summary: {
        total_reports_checked: workReports?.length || 0,
        cost_data_found: costDataToMigrate.length,
        existing_data_skipped: existingReportIds.length,
        new_data_inserted: newDataToInsert.length,
        target_accounting_item: defaultExpenseItem.name
      },
      message: 'Migration completed successfully'
    })

  } catch (error) {
    console.error('âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼:', error)
    return NextResponse.json(
      { error: 'Migration failed', details: error.message },
      { status: 500 }
    )
  }
}